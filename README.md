<h1 align="center"><img src="https://readme-typing-svg.demolab.com?font=Chakra+Petch&weight=500&size=29&duration=1&pause=1000&color=000000&background=601EF9&vCenter=true&repeat=false&width=990&lines=Conversational+Agent+for+Medical+Question-Answering+Using+RAG+and+LLM" alt="Typing SVG" /></h1>

<div align="center">
  <img src="https://i.pinimg.com/originals/7a/7f/b3/7a7fb3decb94644a713454a70e0b5a43.gif" alt="Banner">
</div>

---

<p>
  This  study  analyzes  the  application  of  the  RAG  concept  alongside  an  LLM  in  the  context  of  PubMed  QA  data  to  augment question-answering capabilities in the medical context.For answering questions relevant to private healthcare institutions, the Mistral 7B model was utilized.To limit hallucinations, an embedding model was used for document indexing, ensuring that the LLM answers based on the provided context information.The analysis was conducted using five embedding models, two of which are specialized medical models, PubMedBERT-base and BioLORD-2023, as well as three general models, GIST-large-Embedding-v0, blade-embed-kd, and all-MiniLM-L6-v2. As the results showed, general models performed better than  domain specific models, especially GIST-large-Embedding-v0 and b1ade-embed-kd, which underscores the dominance of general-purpose training datasets in terms of fundamental semantic retrieval, even in medical domains. The outcome of this research study demonstrates that applying RAG and LLM locally can safeguard privacy while still  responding  to  medical  queries  with  appropriate  precision,  thus  establishing  a  foundation  for  a  dependable  medical  question-answering system.
</p>
